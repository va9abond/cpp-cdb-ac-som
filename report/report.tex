\documentclass[a4paper,12pt]{report}
% book report(no part) article(no part/section) letter slides
%      ------          -------
% chapter c section c subsection c subsubsection c paragraph c subparagraph

\input{preamble}
\input{graphs}
\input{macros}
\input{letterfonts}

\title{Отчет по курсовой работе\\"Построение нейронной сети Кохонена"}
\author{КМБО-01-21, Рустем Сиразетдинов}

\begin{document}

    \maketitle
    \newpage
    \tableofcontents
    \pagebreak

\chapter{Предисловие}
В современном мире работа исследователей все чаще направлена на
изучение и развитие \textit{искусственного интеллекта} (далее -
ИИ). Работы в этой области обладают значительным
прикладным потенциалом. Но уже сейчас их применение
крайне разнообразно: предсказание заболеваний на основе анализов человека,
распознавание биометрических данных, обработка больших данных и предсказания на их основе, голосовые
ассистенты, компьютерное зрение и тд.
Особое место занимает генеративный искусственный интеллект,
создающий, например, мультимедийные материалы или тексты,
неотличимые от результатов человеческих усилий.

Все это результаты ученых, пытающихся создать структуры подобные человеческой нервной
системе в цифровом пространстве. Mы, конечно, имеем ввиду
\textit{искусственные нейронные сети} (далее - нейронные сети) - одна из самых
популярных и успешных реализаций ИИ, воссоздающая нервную систему
человека лишь с некоторыми упрощениями. Конечно, здесь невозможно не
упомянуть и огромную работу нейробилогов, предоставляющих
информацию о нервной системе человека, а также все серьезные проблемы
урегулирования развития ИИ, однако оставим их рассмотрение за рамками текущего отчета.

В этой работе мы постараемся дать некоторые начальные положения
устройства и работы нейронных сетей, более подробно рассмотрим саморегулирующиеся сети, что представляют класс
сетей с обучением без подкрепления, приведем реализацию такой
нейронной сети и продемонстрируем ее работу на примере задачи
распознавания цифр.

\chapter{Введение} \label{chapter:Introduction}
\section{Знакомство с нейронными сетями}
Исследования по нейронным сетям связаны с тем, что способ обработки
информации человеческим мозгом в корне отличается от методов,
применяемых обычными цифровыми компьютерами. Мозг представляет собой
сложный, нелинейный, параллельный компьютер. Важная его особенность
заключается в организации своих структурных компонент, называемых
\textit{нейронами}, так, чтобы они могли выполнять конкретные задачи
во много раз быстрее, чем могут позволить самые быстродействующие
современные компьютеры. Примером такой задачи обработки информации
служит обычное \textit{зрение}. В функции зрительной системы входит
создание представления окружающего мира в таком виде, который
обеспечивает возможность взаимодействия с этим миром. Т.е. мозг
последовательно выполняет ряд задач распознавания и на это ему
требуется порядка 100-200 миллисекунд, в то время как выполнение
аналогичных задач даже меньшей сложности на компьютере может занять
несколько дней.

Что позволяет мозгу достичь такого результата? Дело в том, что
при рождении мозг человека крайне \textit{пластичен}, т.е. легко позволяет
нервной системе подстраиваться (настраивать нейроны и синопсисы) под окружающую среду на основе
накапливающегося опыта. Аналогично, в искусственных нейронных сетях
работа проводится искусственными нейронами, которые прошли процесс
\textit{обучения}. Процедура, использующаяся для процесса обучения,
называется \textit{алгоритмом обучения}. Ее задача состоит в
выстраивании в определенном порядке синаптических весов сети для
обеспечения правильных взаимосвязей между самими нейронами. Таким
образом мы пришли к следующему определению искусственной нейронной
сети.

\begin{quote}
    \textbf{Нейронная сеть} - это распределенный параллельный
    процессор, состоящий из элементарных единиц обработки информации,
    накапливающих экспериментальные знания и предоставляющих их для
    последующей обработки.
\end{quote}

\section{Модели нейронов}
\textit{Нейрон} представляет собой единицу обработки информации в
нейронной сети. На рис. \ref{fig:unlinear neuron model} показана модель нейрона, лежащего в
основе нейронных сетей. В модели можно выделить три основных элемента.

\begin{figure}[!htb]
\centering
\resizebox{0.50\paperwidth}{!}{%
    \begin{tikzpicture}
        \tikzstyle{vertex}=[auto=left,circle,fill=orange!25,opacity=.8,
            draw=orange,minimum size=20pt,inner sep=0pt]

            \node[vertex] (n0)  at (-4,3) {$\omega_{k0}$};
            \node[left = 1.5cm of n0] (x0) at (n0) {$x_0=+1$};

            \node[above right=.3cm of n0] (i0) at (n0)
            {$\omega_{k0}=b_k$};

            \foreach \t in {1, 2, 3}
            {
                \node[vertex] (n\t)  at (-4,3-1.5*\t)    {$\omega_{k\t}$};
                \node[left = 1.5cm of n\t] (x\t) at (n\t) {$x_\t$};
            }

            \node[vertex] (nm)  at (-4,-4)   {$\omega_{km}$};
            \node[left = 1.5cm of nm] (xm) at (nm) {$x_m$};
            \path (n3) -- (nm) node [black, font=\huge, midway]
            {$\vdots$};
            \path (x3) -- (xm) node [black, font=\huge, midway]
            {$\vdots$};

            \node[circle, fill=orange!25, opacity=.8,draw=orange,
            minimum size=35pt,inner sep=0pt] (sum) at (-1.5,0)
            {$\Sigma$};

            \foreach \t in {0, 1, 2, 3, m}
            {
                \draw[Circle-Stealth, shorten >=2pt] (x\t) -- (n\t);
                \draw[-Stealth, shorten <=1pt, shorten >=2pt] (n\t) --
                (sum);
            }

            \node[rectangle, fill=blue!25, opacity=.8, draw=blue, minimum
            height=0.7cm, minimum width=1.2cm] (func)
            at (1,0) {$\varphi(\cdot)$};
            \draw[-Stealth, shorten <=1pt, shorten >=2pt] (sum) --
            (func) node[fill=white, inner sep=2pt, midway] {$v_k$};

            \node (result) at (2.8,0) {$y_k$};
            \draw[-{Stealth}{Stealth}, shorten <=1pt] (func) --
            (result);

            \draw[thick, decorate, decoration={calligraphic brace}]
            (-6.3,-4.2) -- (-6.3,1.7);
    \end{tikzpicture}
    }
    \caption{Нелинейная модель нейрона}
    \label{fig:unlinear neuron model}
\end{figure}

\begin{enumerate}
    \item Набор \textit{синапсов}, каждый из которых характеризуется своим
        весом. В частности сигнал $x_j$ на входе синапса $j$,
        связанного с нейроном $k$, умножается на вес $\omega_{kj}$.
        Синаптический вес нейрона может иметь как положительные, так и
        отрицательные значения.
    \item \textit{Сумматор} складывает входные сигналы, взвешенные относительно
        соответствующих синапсов нейрона. Эта операция представляет
        собой линейную комбинацию.
    \item \textit{Функция активации} ограничивает значения выходного
        сигнала нейрона, так чтобы он лежал в диапазоне $[0,1]$ или
        $[-1,1]$.
\end{enumerate}

Очень часто в модель нейрона включают и пороговый элемент,
обозначенный на рис. \ref{fig:unlinear neuron model} символом $b_k$. Эта величина отражает
увеличение или уменьшение входного сигнала $v_k$, подаваемого на функцию
активации. Другими словами, использование порога $b_k$ обеспечивает
эффект аффинного преобразования выхода линейного сумматора $u_k$ см.
рис. \ref{fig:b_k}.

\begin{figure}[!h]
    \centering
    \begin{tikzpicture}
        \centering
        \draw[step=1cm,gray,very thin] (-2.9,-2.9) grid (2.9,2.9);
        \draw[thick,->] (0,-3) -- (0,3) node[anchor=south east]
        {$v_k$};
        \draw[thick,->] (-3, 0) -- (3,0) node [anchor=north west]
        {$u_k$};
        \draw[thick,-]  (-3,-1.5) -- (1, 2.5) node [above right]
        {$b_k>0$};
        \draw[dashed,-]  (-2,-2) -- (2,2) node [above right]
        {$b_k = 0$};
        \draw[thick,-]  (-1,-2.5) -- (3, 1.5) node [above right]
        {$b_k<0$};

        \draw[ultra thick, draw=black, fill=gray, opacity=0.15]
        (-3,-1.5) -- (1, 2.5) -- (3, 1.5) -- (-1,-2.5) -- cycle;

        \filldraw[black] (0,0) circle (2pt) node [anchor=north west]
        {$0$};
    \end{tikzpicture}
    \caption{Аффинное преобразование, вызванное наличием порогового
    элемента $b_k$.} \label{fig:b_k}
\end{figure}

В математическом представлении функционирование нейрона $k$ можно
описать следующей парой уравнений:
\begin{equation}
    \begin{aligned}
        u_k &= \sum^{m}_{j=1}{\omega_{kj}x_j},\\
        y_k &= \varphi(v_k),\, v_k = u_k + b_k
    \end{aligned}
\end{equation}
где $x_1, x_2, \dots, x_m$ - входные сигналы; $\omega_{k1},
\omega_{k2}, \dots, \omega_{km}$ - синаптические веса нейрона $k$;
$u_k$ - линейная комбинация входных сигналов; $b_k$ - величина
порогового элемента; $\varphi(\cdot)$ - функция активации; $y_k$ -
выходной сигнал нейрона.

\section{Типы функций активации}
Функции активации определяют выходной сигнал нейрона в зависимости от
входного сигнала $v$. Можно выделить три основных типа функции
активации.

\begin{enumerate}
    \item \textit{Функция единичного скачка}, или пороговая функция.
        Этот тип показан на рис. \ref{fig:threshold func} и описывается следующим образом:
        \begin{equation}
            \varphi(v) =
            \begin{cases}
                1,& \text{если}\ v \geq 0; \\
                0,& \text{если}\ v < 0;
            \end{cases}
        \end{equation}

    Соответственно выходной сигнал нейрона $k$ такой функции можно
    представить как
        \begin{equation}
                y_k =
                \begin{cases}
                    1,& \text{если}\ v_k \geq 0; \\
                    0,& \text{если}\ v_k < 0;
                \end{cases}\quad
                v_k = \sum^{m}_{j=1}{\omega_{kj}x_j + b_k.}
        \end{equation}

    \item \textit{Кусочно-линейная функция}. Кусочно-линейная функция
        показанная на рис. \ref{fig:piecewise-linear func},
        описывается следующим выражением:
        \begin{equation}
            \varphi(v) =
                \begin{cases}
                    0    ,& v \leq -0.5, \\
                    \beta|v| ,& 0.5 > v > -0.5; \\
                    1    ,& v \geq 0.5;
                \end{cases}
        \end{equation}
        где коэффициент $\beta$ усиления в линейной области предполагается
        равным единице.

    \item \textit{Сигмоидальная функция}. Сигмоидальная функция,
        график, которой изображен на рис. \ref{fig:sigmoid func},
        является наиболее распространенной для создания нейронных
        сетей. Она поддерживает баланс между линейным и нелинейным
        поведением. Примером сигмоидальной функции может служить
        логистическая функция (рис. \ref{fig:sigmoid func other}), задаваемая выражением:
        \begin{equation}
        \varphi(v) = \frac{1}{1+\exp(-\alpha v)},
        \end{equation}
        где $\alpha$ - параметр наклона сигмоидальной функции,
        отвечающий за то, как быстро или медленно функция будет
        возрастать в линейной своей части.

\end{enumerate}


\begin{figure}[!htb]
    \centering
    \subfloat[Пороговая функция \label{fig:threshold func}]{%
        \resizebox{0.30\paperwidth}{!}{%
        \begin{tikzpicture}[domain=-2:2]
            \begin{axis}[%
                xlabel = $v$,
                ylabel = $\varphi(v)$,
                grid=major,
                % axis x line = bottom, axis y line = left,
                ytick={0.2, 0.4, ..., 1},
                ymax=1.2%
                ]

                \addplot+[const plot, no marks, very thick]
                coordinates {(-2,0) (0,0) (0,1) (2,1)};

            \end{axis}
        \end{tikzpicture}
        }
    }
    \hspace{10pt}
    \centering
    \subfloat[Кусочно-линейная функция \label{fig:piecewise-linear func}]{%
        \resizebox{0.30\paperwidth}{!}{%
        \begin{tikzpicture}[domain=-2:2]
            \begin{axis}[%
                    xlabel = $v$,
                    ylabel = $\varphi(v)$,
                    grid=major,
                    % axis x line = bottom, axis y line = left,
                    ytick={0.2, 0.4, ..., 1},
                    ymax=1.2,%
                    ]

                    \addplot[blue, no marks, very thick]
                    coordinates {(-2,0) (-0.5,0) (0.5,1) (2,1)};

            \end{axis}
        \end{tikzpicture}
        }
    }
    \hspace{10pt}
    \centering
    \subfloat[Сигмоидальная функция \label{fig:sigmoid func}]{%
        \resizebox{0.30\paperwidth}{!}{%
        \begin{tikzpicture}[domain=-6:6]
            \begin{axis}[%
                    xlabel = $v$,
                    ylabel = $\varphi(v)$,
                    grid=major,
                    % axis x line = bottom, axis y line = left,
                    ytick={0.2, 0.4, ..., 1},
                    ymax=1.2%
                    ]

                \addplot[blue,smooth, very thick] {1/(1+exp(-x))};

            \end{axis}
        \end{tikzpicture}
        }
    }
    \hspace{10pt}
    \centering
    \subfloat[Логистическая функция \label{fig:sigmoid func other}]{%
        \resizebox{0.30\paperwidth}{!}{%
        \begin{tikzpicture}[domain=-6:6]
            \begin{axis}[%
                    xlabel = $v$,
                    ylabel = $\varphi(v)$,
                    grid=major,
                    ytick={0.2, 0.4, ..., 1},
                    ymax=1.2%
                    ]

                    \foreach \t in {0.4, 0.6, 1.8}
                    {
                        \addplot[blue,smooth, very thick] {1/(1+exp(-(\t * x))};
                    }

            \end{axis}
        \end{tikzpicture}
        }
    }
    \caption{Примеры разных типов функции активации}
\end{figure}

Мы рассмотрели несколько примеров функций активации, у каждой из них
область значений представляется отрезком $[0,1]$. Однако иногда
требуется функция активации, имеющая область значений отрезок
$[-1,1]$. В этом случае мы хотим от нее симметричности относительно
начала координат, в частности, мы может определить пороговую
функцию (рис. \ref{fig:sgn}):
\begin{equation*}
    \varphi(v) = sgn(v) =
    \begin{cases}
        -1,& v < 0, \\
        0 ,& v = 0, \\
        1 ,& v > 0.
    \end{cases}
\end{equation*}
Еще отличным примером сигмоидальной функции будет служить
гиперболический тангенс (рис. \ref{fig:tanh}): $$\varphi(v) = \tanh(v)$$

\begin{figure}[!hbt]
    \centering
    \subfloat[Сигнум \label{fig:sgn}]{
            \begin{tikzpicture}
            \begin{axis}[%
                    grid=major,
                    width=6.25cm,
                    height=5cm,
                    ylabel=$\varphi(v)$,
                    xlabel=$v$,
                    ymin=-1.2,
                    ymax=1.2,
                    xmin=-5,
                    xmax=5
                ]
                \addplot+[const plot, blue, no marks, very thick]
                coordinates {(-4,-1) (0, -1)};

                \addplot+[const plot, blue, no marks, very thick]
                coordinates {(0,1) (4, 1)};

                \filldraw[black] (0,0) circle (2pt);
                \draw[fill=white, draw=black] (0,-1) circle (2pt);
                \draw[fill=white, draw=black] (0, 1) circle (2pt);
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{10pt}
    \subfloat[Гиперболический тангенс \label{fig:tanh}]{
        \begin{tikzpicture}
            \begin{axis}[%
                    grid=major,
                    width=6.25cm,
                    height=5cm,
                    ylabel=$\varphi(v)$,
                    xlabel=$v$,
                    ymin=-1.2,
                    ymax=1.2,
                    xmin=-5,
                    xmax=5
                ]
                \addplot[blue,smooth, very thick] {tanh(x)};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Примеры разных типов функции активации
    (продолжение)}
\end{figure}

\section{Алгоритмы и нейронные сети}
До появления науки о нейронных сетях уже была существенно развита
теория алгоритмов, которая успешно использовалась учеными и
разработчиками того времени, так какие недостатки алгоритмов пришлось
закрывать созданием нейронных сетей?

Давайте рассмотрим, какие задачи выполняет алгоритм? Сам по себе
каждый алгоритм, конечно, является набором инструкций для
вычислительной машины, помимо этого, он призван решить конкретную
проблему, например, набор инструкций для сортировки значений
контейнера, увеличение скорости обращения к объектам с помощью
кэширования, создания отказоустойчивости и надежности с помощью
алгоритмов создания журналов, документации о релевантных событиях.
Однако, кроме этого, мы ожидаем от алгоритмов эффективности в работе,
например, качество и скорость сжатия данных, т.е. не каждый набор
инструкций мы определим как алгоритм. Таким образом, алгоритм
обеспечивает систематический и логический подход к решению задачи.

Во внутреннем устройстве нейронных сетей тоже участвуют алгоритмы, но
тогда чем же алгоритмы и нейронные сети отличаются? Главным и самым
важным отличием и преимуществом
нейронных сетей над алгоритмами является их способность к обучению -
способность давать правильные и \textit{новые} ответы на наборах данных,
которые никогда ранее не встречались и улучшать свои же ответы на
неоднократно протестированных входных данных. Нейронные сети в процессе
обучения и работы способны обнаруживать сложные связи между изучаемыми
объектами, в то время как разработчики могли и не догадываться об их
существовании. При работе с алгоритмом все его множество ответов было
заранее заложено в него во время проектирования.

\paragraph{Преимущества нейронных сетей}
\begin{enumerate}
    \item \textit{Нелинейность}. Нелинейность является чрезвычайно важным
        свойством, когда сам физический механизм, отвечающий за
        формирование входного сигнала, тоже является нелинейным
        (например, человеческая речь).
    \item \textit{Отображение входной информации в выходную}. Обучение с
        учителем подразумевает изменение синаптических весов на основе
        маркированных учебных примеров. Каждый пример состоит из
        входного сигнала и соответствующего ему желаемого отклика.
        Нейронная сеть модифицирует веса для минимизации расхождений
        желаемого выходного сигнала и формируемого сетью. Таким
        образом, нейронная сеть обучается на примерах, составляя
        таблицу соответствий вход-выход для конкретной задачи.
    \item \textit{Адаптивность}. Нейронные сети обладают способность адаптации
        синаптических весов к изменениям окружающей среды. В
        частности, нейроны, обученные действовать в определенной
        среде, могут быть легко переучены для работы в условиях
        незначительных колебаний параметров среды. А для работы в
        нестационарной среде могут быть созданы нейронные сети,
        изменяющие синоптические веса в реальном времени.
    \item \textit{Очевидность ответа}. В контексте задачи классификации образов
        можно разработать нейронную сеть, собирающую информацию не
        только для определения конкретного класса, но и для увеличения
        достоверности принимаемого решения. Впоследствии эта
        информация может быть использована для исключения сомнительных
        решений.
\end{enumerate}

Помимо упомянутых выше преимуществ нейронной сети стоит упомянуть и
другие: отказоустойчивость, масштабируемость, контекстная информация,
единообразие анализа и проектирования. Более подробно с ними читатель
может ознакомиться, например, в [TODO].

\section{Представление нейронных сетей с помощью направленных графов}


\section{Приложения нейронных сетей}
Мы хотели бы завершить главу \nameref{chapter:Introduction},
рассмотрев несколько примеров использования нейронных сетей в реальном
мире.

\section{Реализация}

\section{Заключение}

\end{document}
